确保安全、可靠、可控
兼顾人工智能应用和隐私保护（势所必然）

　　作为新一轮科技革命和产业变革的重要驱动力量，人工智能正在深刻影响社会生活、改变发展格局。同时，人工智能如同一把“双刃剑”，如果应用不当，就可能带来隐私泄露的伦理风险。如何在人工智能应用中兼顾隐私保护，确保安全、可靠、可控，是一项亟须关注的伦理课题。
　　人工智能应用存在隐私泄露的伦理风险。人工智能应用需要以海量的个人信息数据作支撑。数据是人工智能的基础，正是由于大数据的使用、算力的提高和算法的突破，人工智能才能快速发展、广泛应用，并呈现出深度学习、跨界融合、人机协同、群智开放、自主操控等新特征。人工智能越是“智能”，就越需要获取、存储、分析更多的个人信息数据。可以说，海量信息数据是人工智能迭代升级不可缺少的“食粮”。获取和处理海量信息数据，不可避免会涉及个人隐私保护这一重要伦理问题。今天，各类数据信息采集无时不有、无处不在，几乎每个人都被置于数字化空间之中，个人隐私极易以数据的形式被存储、复制、传播，如个人身份信息数据、网络行为轨迹数据以及对数据处理分析形成的偏好信息、预测信息等。可以预见，在不远的未来，越来越多的人工智能产品将走进千家万户，在给人们生活带来便利的同时，也会轻易获取更多有关个人隐私的数据信息。借助获取的数据信息，基于日益强大的数据整合、处理能力，人工智能技术可以为用户精准“画像”，而其中就潜藏着不容忽视的隐私泄露风险。如果人工智能应用得不到合理管控，人类将被置于隐私“裸奔”的尴尬境地，从而产生严重的伦理风险。
　　人工智能应用与隐私保护并非不可兼得。尽管人工智能应用在一定程度上存在隐私泄露的风险，但这并不意味着它与隐私保护之间是绝对对立的关系。一方面，人工智能应用决不能以隐私泄露为代价。隐私权不容侵犯，它既是公民的基本权利，也是社会文明进步的显著标志。有效保护隐私有利于人们维护人格尊严、保持心情舒畅，有利于促进人的全面发展。人工智能技术无论如何发展、发展到什么程度，归根结底都是为了辅助人、服务人，为使用者提供便利，而不能成为肆意损害人格权利、恶意泄露个人隐私的工具。这是人工智能应用必须坚守的底线，否则人工智能技术就会失去价值，也难以走远。另一方面，不能因为存在隐私泄露的伦理风险，就延缓甚至放弃人工智能应用。目前，人工智能应用得到世界主要国家的高度重视，被认为是科技创新的下一个“超级风口”，具有溢出带动性很强的“头雁”效应。在一定程度上讲，谁把握住了人工智能技术，谁就把握住了未来。加快发展新一代人工智能技术，是我国发展必须牢牢抓住的宝贵机遇。我们既要有效防范伦理风险，又要加快人工智能技术发展。事实上，人工智能应用与个人隐私保护之间并不是非此即彼的关系，完全可以通过多种手段从伦理层面对人工智能应用加以正确引导，将隐私泄露的风险降至最低。作为一种新兴技术，人工智能本身并无善恶、对错之分，关键在于使用者能否在符合伦理规范的前提下对其进行正当应用。隐私泄露现象是人工智能应用不当导致的，从深层看则大多是利益驱动的结果。所以，不能将隐私泄露简单归为技术层面的问题，也不能简单归咎于人工智能。
　　在推进人工智能应用中加强隐私保护。习近平同志强调，要加强人工智能发展的潜在风险研判和防范，维护人民利益和国家安全，确保人工智能安全、可靠、可控。在人工智能应用中加强隐私保护，需要加强人工智能应用的风险研判和防范，综合运用技术创新、伦理规范、法律制度等手段方式，防止其“野蛮生长”，确保在符合伦理规范的前提下实现人工智能健康发展。在技术层面，要加快研发和应用隐私保护的安全技术，可将用户隐私保护需求嵌入人工智能系统设计中，让最大限度保护隐私成为系统的默认规则。在伦理层面，要探索和确立保护个人隐私的原则。2019年6月17日，我国新一代人工智能治理专业委员会发布《新一代人工智能治理原则——发展负责任的人工智能》，要求人工智能发展应尊重和保护个人隐私，充分保障个人的知情权和选择权。人工智能从业人员要树立社会主义核心价值观，加强自律，规范技术应用的标准、流程、方法，最大限度尊重和保护个人隐私。在法律层面，应加快制定加强隐私保护的法规制度。当前，我国隐私保护法律体系还不能完全适应人工智能发展需求，应在相关法律法规中进一步强化隐私权保护，并在条件成熟时制定针对人工智能应用中保护公民隐私的法律条文细则，充分保障公民在人工智能应用中的知情权和选择权，严格规范人工智能应用中个人信息的收集、存储、处理、使用等程序，反对窃取、篡改、泄露和其他非法收集利用个人信息的行为。
　　（作者为南京艺术学院教授、江苏省伦理学会执行会长）
